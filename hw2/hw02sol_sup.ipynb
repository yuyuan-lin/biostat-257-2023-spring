{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Biostat/Biomath M257 Homework 2 supplemental materials\n",
    "subtitle: 'Due Apr 28 @ 11:59PM'\n",
    "author: Yuyuan Lin (804886544)\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    theme: cosmo\n",
    "    embed-resources: true\n",
    "    number-sections: true\n",
    "    toc: true\n",
    "    toc-depth: 4\n",
    "    toc-location: left\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This supplement is for GPU computation **Q1.7**. Since the Macbook Pro I am using has an Apple silicon GPU, and the `Metal` package for that is still under development. To show the potential of GPU computation, I have this supplement for a Windows PC with a NVIDIA GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.8.5\n",
      "Commit 17cfb8e65e (2023-01-08 06:45 UTC)\n",
      "Platform Info:\n",
      "  OS: Windows (x86_64-w64-mingw32)\n",
      "  CPU: 20 Ã— 12th Gen Intel(R) Core(TM) i7-12700KF\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-13.0.1 (ORCJIT, goldmont)\n",
      "  Threads: 18 on 20 virtual cores\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 18\n"
     ]
    }
   ],
   "source": [
    "# The following codes are excuted on a PC with NVIDIA GTX 3080 GPU\n",
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA runtime 12.1, artifact installation\n",
      "CUDA driver 12.1\n",
      "NVIDIA driver 531.61.0\n",
      "\n",
      "Libraries: \n",
      "- CUBLAS: 12.1.0\n",
      "- CURAND: 10.3.2\n",
      "- CUFFT: 11.0.2\n",
      "- CUSOLVER: 11.4.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- CUSPARSE: 12.0.2\n",
      "- CUPTI: 18.0.0\n",
      "- NVML: 12.0.0+531.61\n",
      "\n",
      "Toolchain:\n",
      "- Julia: 1.8.5\n",
      "- LLVM: 13.0.1\n",
      "- PTX ISA support: 3.2, 4.0, 4.1, 4.2, 4.3, 5.0, 6.0, 6.1, 6.3, 6.4, 6.5, 7.0, 7.1, 7.2\n",
      "- Device capability support: sm_37, sm_50, sm_52, sm_53, sm_60, sm_61, sm_62, sm_70, sm_72, sm_75, sm_80, sm_86\n",
      "\n",
      "1 device:\n",
      "  0: NVIDIA GeForce RTX 3080 (sm_86, 6.770 GiB / 10.000 GiB available)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools, DelimitedFiles, Images, LinearAlgebra, LoopVectorization\n",
    "using Profile, Random\n",
    "using CUDA\n",
    "\n",
    "CUDA.versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "X = readdlm(\"nnmf-2429-by-361-face.txt\")\n",
    "V0full = readdlm(\"V0.txt\", ' ', Float64)\n",
    "W0full = readdlm(\"W0.txt\", ' ', Float64)\n",
    "println(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmf (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function nnmf(\n",
    "    # positional arguments\n",
    "    X       :: AbstractMatrix{T}, \n",
    "    r       :: Integer;\n",
    "    # kw arguments\n",
    "    maxiter :: Integer = 1000, \n",
    "    tolfun  :: Number = 1e-4,\n",
    "    V       :: AbstractMatrix{T} = Random.rand!(similar(X, size(X, 1), r)),\n",
    "    W       :: AbstractMatrix{T} = Random.rand!(similar(X, r, size(X, 2))),\n",
    "    ) where T <: AbstractFloat\n",
    "    # implementation\n",
    "    ## initialization and preallocation\n",
    "    obj0, obj, niter = 0.0, 1.0, 0\n",
    "    m, n = size(X)\n",
    "    XWt = similar(X, m, r)\n",
    "    VtX = similar(X, r, n)\n",
    "    WWt = W * transpose(W)\n",
    "    VtV = similar(X, r, r)\n",
    "    VWWt = similar(X, m, r)\n",
    "    VtVW = similar(X, r, n)\n",
    "    trXtX = norm(X, 2)^2\n",
    "    WtVtX = similar(X, n, n)\n",
    "    WWtVtV = similar(X, r, r)\n",
    "    \n",
    "    ## main loop\n",
    "    while (abs(obj - obj0)) / (abs(obj0 + 1)) >= tolfun && niter < maxiter\n",
    "        # update V\n",
    "        mul!(XWt, X, transpose(W))\n",
    "        mul!(VWWt, V, WWt) # WWt was updated later in the loop\n",
    "        V .= V .* XWt ./ VWWt\n",
    "        # update W\n",
    "        mul!(VtX, transpose(V), X)\n",
    "        mul!(VtV, transpose(V), V)\n",
    "        mul!(VtVW, VtV, W)\n",
    "        W .= W .* VtX ./ VtVW\n",
    "        # update niter and obj\n",
    "        obj0 = obj\n",
    "        mul!(WWt, W, transpose(W))\n",
    "        mul!(WtVtX, transpose(W), VtX)\n",
    "        mul!(WWtVtV, WWt, VtV)\n",
    "        obj = trXtX - 2 * tr(WtVtX) + tr(WWtVtV)\n",
    "        niter += 1\n",
    "    end\n",
    "    \n",
    "    # Output\n",
    "    V, W, obj, niter\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU performance (single precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  33.856 ms (88712 allocations: 3.90 MiB)\n",
      "GPU performance (double precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  222.383 ms (101907 allocations: 4.75 MiB)\n",
      "CPU performance (single precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  160.860 ms (13 allocations: 729.16 KiB)\n",
      "CPU performance (double precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  204.625 ms (13 allocations: 1.42 MiB)\n",
      "r=20\n",
      "GPU performance (single precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  64.787 ms (147598 allocations: 6.49 MiB)\n",
      "GPU performance (double precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  257.406 ms (161970 allocations: 7.43 MiB)\n",
      "CPU performance (single precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  559.958 ms (15 allocations: 950.84 KiB)\n",
      "CPU performance (double precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  577.099 ms (13 allocations: 1.86 MiB)\n",
      "r=30\n",
      "GPU performance (single precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  74.973 ms (172932 allocations: 7.60 MiB)\n",
      "GPU performance (double precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  339.337 ms (204949 allocations: 9.54 MiB)\n",
      "CPU performance (single precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1.180 s (15 allocations: 1.15 MiB)\n",
      "CPU performance (double precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1.026 s (13 allocations: 2.29 MiB)\n",
      "r=40\n",
      "GPU performance (single precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  105.787 ms (215135 allocations: 9.46 MiB)\n",
      "GPU performance (double precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  574.992 ms (247516 allocations: 11.52 MiB)\n",
      "CPU performance (single precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.311 s (15 allocations: 1.37 MiB)\n",
      "CPU performance (double precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1.264 s (13 allocations: 2.73 MiB)\n",
      "r=50\n",
      "GPU performance (single precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  135.016 ms (260235 allocations: 11.45 MiB)\n",
      "GPU performance (double precision): \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  801.783 ms (297569 allocations: 13.86 MiB)\n",
      "CPU performance (single precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6.293 s (16 allocations: 1.59 MiB)\n",
      "CPU performance (double precision): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1.894 s (16 allocations: 3.18 MiB)\n",
      "FINISH"
     ]
    }
   ],
   "source": [
    "# convert X, W0full, V0full as single precision matrix and transfer to GPU\n",
    "Xsp  = convert(Array{Float32}, X)\n",
    "Xspd = CuArray(Xsp)\n",
    "Xd   = CuArray(X)\n",
    "V0fullsp   = convert(Array{Float32}, V0full)\n",
    "V0fullspd  = CuArray(V0fullsp)\n",
    "V0fulld    = CuArray(V0full)\n",
    "W0fullsp   = convert(Array{Float32}, W0full)\n",
    "W0fullspd  = CuArray(W0fullsp)\n",
    "W0fulld    = CuArray(W0full)\n",
    "# benchmark on GPU and CPU\n",
    "for r in [10, 20, 30, 40, 50]\n",
    "    println(\"r=$r\")\n",
    "    V0spd = V0fullspd[:, 1:r]\n",
    "    W0spd = W0fullspd[1:r, :]\n",
    "    V0d = V0fulld[:, 1:r]\n",
    "    W0d = W0fulld[1:r, :]\n",
    "    V0sp = V0fullsp[:, 1:r]\n",
    "    W0sp = W0fullsp[1:r, :]\n",
    "    V0 = V0full[:, 1:r]\n",
    "    W0 = W0full[1:r, :]\n",
    "    println(\"GPU performance (single precision): \")\n",
    "    @btime nnmf($Xspd, $r, V = $V0spd, W = $W0spd) setup = (\n",
    "        copyto!($V0spd, $V0fullspd[:, 1:$r]),\n",
    "        copyto!($W0spd, $W0fullspd[1:$r, :])\n",
    "    )\n",
    "    println(\"GPU performance (double precision): \")\n",
    "    @btime nnmf($Xd, $r, V = $V0d, W = $W0d) setup = (\n",
    "        copyto!($V0d, $V0fulld[:, 1:$r]),\n",
    "        copyto!($W0d, $W0fulld[1:$r, :])\n",
    "    )\n",
    "    println\n",
    "    println(\"CPU performance (single precision): \")\n",
    "    @btime nnmf($Xsp, $r, V = $V0sp, W = $W0sp) setup = (\n",
    "        copyto!($V0sp, $V0fullsp[:, 1:$r]),\n",
    "        copyto!($W0sp, $W0fullsp[1:$r, :])\n",
    "    )\n",
    "    println(\"CPU performance (double precision): \")\n",
    "    @btime nnmf($X, $r, V = $V0, W = $W0) setup = (\n",
    "        copyto!($V0, $V0full[:, 1:$r]),\n",
    "        copyto!($W0, $W0full[1:$r, :])\n",
    "    )\n",
    "end\n",
    "print(\"FINISH\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the `CUDA` package provides us the high efficiency on computation, and GPU beat CPU in both `Float32` and `Float64` computation (except for the case when $r=10$). And it is obvious that GPU is extremely efficient in single precision computation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
